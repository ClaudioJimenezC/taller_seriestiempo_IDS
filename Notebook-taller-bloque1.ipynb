{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloque 1: Naturaleza de las series de tiempo\n",
    "\n",
    "Melanie Oyarzún W.\n",
    "\n",
    "\n",
    "**Resultado de aprendizaje esperado:**\n",
    "\n",
    "Identificar datos de series temporales, sus particularidades y riesgos, en el contexto de posibles aplicaciones profesionales.\n",
    "\n",
    "**Bibliografía recomendada:**\n",
    "\n",
    "Stock & Watson, C.14 [link](https://www.dropbox.com/s/d09qcat340jy5q2/stock%20y%20watson%20-%20Introduccion%20a%20la%20Econometria.pdf?dl=0) ; Wooldridge, c.12 [link](https://www.dropbox.com/s/wrh0tuna27qp747/Wooldridge__Introductory_Econometrics_2nd_Ed_Solutions.pdf?dl=0), Gujarati, c.12  [link](https://www.dropbox.com/s/rrvth8vsa1c5gts/Gujarati-cap%2012.pdf?dl=0)\n",
    "\n",
    "**Material de apoyo***\n",
    "\n",
    "El taller cuenta con un repositorio  [https://github.com/melanieoyarzun/taller_IDS2021](https://github.com/melanieoyarzun/taller_IDS2021) en el cual está dispoinible todo el material.\n",
    "\n",
    "**Slides**\n",
    "\n",
    "Estan disponibles en el repositorio o directamente en el link \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paquetes y settings\n",
    "\n",
    "from dateutil.parser import parse \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import watermark\n",
    "\n",
    "\n",
    "#%matplotlib inline\n",
    "%load_ext watermark\n",
    "\n",
    "# setting de graficos\n",
    "\n",
    "plt.figure(figsize=(5,3), dpi= 200, facecolor='w', edgecolor='k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tipos de datos\n",
    "\n",
    "Los datos que analizamos con modelos se pueden categorizar en tres grandes tipos: \n",
    "\n",
    "- corte transversal \n",
    "- series de tiempo (o longitudinal)\n",
    "- panel\n",
    "\n",
    "## Corte transversal\n",
    "Cuando se empieza a estudiar modelamiento de datos, la aplicación natural de estos es en lo que llamamos datos de corte transversal. En estos, la **unidad de observación** son individuos separados unos de otros. \n",
    "\n",
    "Usualmente, cada fila reprsenta un individuo (personas, familias, empresas) en un momento del tiempo específico (mismo año, mismo mes, etc). Es análogo a una *fotografía* de do grupo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ejemplo de esto es la encuesta Casen [(http://observatorio.ministeriodesarrollosocial.gob.cl/encuesta-casen)](http://observatorio.ministeriodesarrollosocial.gob.cl/encuesta-casen) o Encuesta de Caracterización Socioeconómica Nacional.\n",
    "\n",
    "Esta es una encuesta de caracter nacional realizada a hogares, en la cual se busca levantar información para conocer la situación de los hogares y de la población, especialmente de aquella en situación de pobreza y de aquellos grupos definidos como prioritarios y permite evaluar impacto de política social. Es representativa a nivel regional.\n",
    "\n",
    "Es realizada por el Ministerio de Desarrollo Social desde el año 1990 con una periodicidad; bianual o trianual. Hasta ahora, las encuestas aplicadas corresponden a los años 1990, 1992, 1994, 1996, 1998, 2000, 2003, 2006, 2009, 2011, 2013, 2105 y 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_casen2020= pd.read_stata(\"Data/casen_2020_ingresos.dta\")\n",
    "df_casen2020.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_casen2020.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.scatterplot(data=df_casen2020, x=\"esc\", y=\"yaut\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series de tiempo\n",
    "\n",
    "En cambio, un tipo diferente de datos son las **Series Temporales** o tambien longitudinales.\n",
    "\n",
    "En este tipo de información, se tiene diferentes momentos del tiempo (día, semana, mes, año, etc.) para una misma unidad de análisis (individuo, país, empresa, etc)\n",
    "\n",
    "Ejemplos típicos de series de tiempo son: \n",
    "- Datos macroeconómicos (PIB. Inglación, empleo, etc.)\n",
    "- Financieros (precios de acciones)\n",
    "- Empresariales (Ventas, costos, etc...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo datos de acciones\n",
    "\n",
    "#Usemos la api de Yahoo finance: pip install yahoo_fin y pip install requests_html\n",
    "\n",
    "from yahoo_fin.stock_info import get_data\n",
    "\n",
    "amazon_weekly= get_data(\"amzn\", start_date=\"12/04/2009\", end_date=\"12/04/2019\", index_as_date = False, interval=\"1wk\")\n",
    "amazon_weekly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=amazon_weekly, y=\"open\", x=\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uso series de tiempo\n",
    "\n",
    "La información temporal(de series de tiempo) permite responder cómo una variable (o más) responde a cambios a través del tiempo.\n",
    "- ¿Cuál es el efecto causal dinámico de Xt sobre Yt? \n",
    "- ¿Cuál es la mejor predicción del valor de Y en el futuro?\n",
    "  \n",
    "**PERO su uso sin cuidado puede llevarnos a conclusiones MUY equiviocadas**\n",
    "\n",
    "\n",
    "![Ejemplo idotamente peligroso](slide_figuras/spurius.png)\n",
    "\n",
    "\n",
    "(Fuente: [https://www.tylervigen.com/spurious-correlations](https://www.tylervigen.com/spurious-correlations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajar con series de tiempo no es para nada sencillo: **necesitaremos técnicas nuevas.**\n",
    "\n",
    "¿Por qué? \n",
    "\n",
    "Necesitaremos modelos sofisticados de errores y técnicas para estimarlos, por ciertas dieferencias en la naturaleza del **proceso generador de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel\n",
    "\n",
    "El último tipo de datos, es lo que se llama un panel. Este es la combinacion de los dos tipos anteriores, donde para un conjunto de individuos tenemos varias observaciones en el tiempo.\n",
    "\n",
    "Suele ser el tipo de datos más completo, pero tabien más dificil de conseguir. Además, enfrenta los problemas típicos de ambos tipos anteriores, dependiendo si es un panel corto o largo.\n",
    "\n",
    "Una alternativa a etsos son los llamados pooled cross section.\n",
    "\n",
    "Ela análisis de este tipo de datos escapa a los objetivos del taller, pero una introducción pueden revisarla en Stock y Watson Cap. 10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corte transversal vs series de tiempo\n",
    "\n",
    "## Muestras en corte transversal\n",
    "\n",
    "En corte transversal solemos trabajar con **MUESTRAS**\n",
    "\n",
    "![Corte transversal](slide_figuras/datos_st.png)\n",
    "\n",
    "Estimamos modelos de la forma:\n",
    "$$ y_{i}=\\beta_{0}+\\beta_{1}x_{1i}+\\dots+\\beta_{1}x_{ki}+u_{i} $$\n",
    "\n",
    "Estos modelos representan una correlación marginal en las observaciones entre y y x's  (escalada por la varianza de x) y para que podamos interpretarlas causalmente tenemos varias condiciones o supuetsos que de sedeb cumplir.\n",
    "\n",
    "Uno de estos, es el **supuesto de exogeneidad**: $$  E[u_{i}|X_{i}]=0 $$\n",
    "\n",
    "Sin embargo, esta forma de ver este supuesto es una **simplificación** ya que, como estamos en una uestra aleatoria, no tenemos que verificar que los efectos cruzados tambien sean exogenos:\n",
    "\n",
    "$$  E[u_{i}|X_{j}]=0 $$\n",
    "\n",
    "* Esto se daba por cumplido, como consecuencia de que era una muestra aletaoria.\n",
    "* Lo cual, generalente, ocurre en corte transversal por lo cual cada observación es i.i.d.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## La imposibilidad de la muestra en series de tiempo\n",
    "\n",
    "En serie de tiempo, nuestro universo es un proceso estocástico:\n",
    "\n",
    "![Corte transversal](\"/Users/melanie/Dropbox/Asuntos UDD/2021- sem 2/taller_IDS2021/taller_IDS2021-1/slide_figuras/datos_st.png\")\n",
    "\n",
    "Estimamos modelos de la forma:\n",
    "\n",
    "$$ y_{i}=\\beta_{0}+\\beta_{1}x_{1i}+\\dots+\\beta_{1}x_{ki}+u_{i} $$\n",
    "\n",
    "* Estamos en presencia de un **proceso estocástico** \n",
    "* En cada momento se observa un posible resultado (o realización) del proceso estocásticos.\n",
    "\n",
    "Esto tiene vaias implicancias:\n",
    "\n",
    "* NO SON INDEPENDIENTES ya que por construcción, viene del mismo proceso.\n",
    "* Por lo tanto, el supuesto de exogeneidad **$E[u_{i}|X_{i}]=0 $** NO ES SUFICIENTE\n",
    "* Requerimos su versión más exigente: (Exogeneidad estricta)\n",
    "$$E[u_{t}|X_{s}]=0 \\qquad \\forall s $$\n",
    "\n",
    "* Este supuesto, generalmente NO SE CUMPLE.\n",
    "* Si se cumpliese, seguiruíamos operando como siempre con modelos de regresión multiple estándar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué hacer entonces?**\n",
    "\n",
    "Reconocer los datos como procesos estocásticos e incluir sus particularidades en la modelación. De eso se tratarán los dos siguientes bloques\n",
    "- Bloque 2: Peculiaridades de los procesos estocasticos y su exploración en la data\n",
    "- Bloque 3: Modelamiento\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceptos propios de las series de tiempo\n",
    "\n",
    "Dado que una serie de tiempo tiene un orden específico, que en si mismo es importante. En base a este orden se suelen crear nuevos indicadores o variables. Revisemos los más comunes:\n",
    "\n",
    "## Notación y transformaciones:\n",
    "\n",
    "**Notación**\n",
    "\n",
    "* Variables de series de tiempo se denominan con sub-índice t para indicar el perído en el tiempo:   $y_t$\n",
    "* El total de periodos se suele referir como T.\n",
    "\n",
    "### Rezagos \n",
    "\n",
    "* Un **rezago** es el valor de la variable en períodos anteriores:   \n",
    "  * Primer rezago: $y_{t-1}$ es el valor 1 período anterior\n",
    "  * Segundo rezago: $y_{t-2}$ es el valor 2 períodos atrás\n",
    "  * j-ésimo rezago:  $y_{t-j}$ es el valor j períodos atrás\n",
    "\n",
    "### Diferencias\n",
    "\n",
    "Una diferencia corresponde al cambio en una variable entre dos periodos específicos y se usa la notación $\\Delta$\n",
    "\n",
    "* Primera diferencia: $$\\Delta y_t = y_t- y_{t-1}$$\n",
    "\n",
    "### Tasas de crecimiento\n",
    "\n",
    "Si calculamos la primera diferencia el logaritmo natural, podemos obtener incorporar la tasa de crecimiento en una regresión:\n",
    "\n",
    "* Primera diferencia en logs:\n",
    "  $$ \\Delta ln(y_{t})=ln(y_{t})-ln(y_{t-1}) $$\n",
    "\n",
    "* Cambio porcentual de $y_t$  entre $t -1$ y $t\\approx  100\\times \\Delta ln(y_{t})$\n",
    "\n",
    "## Tipos de modelos\n",
    "\n",
    " ### Modelo estático \n",
    "\n",
    " Se modela la relación contemporánea entre dos variables, i.e., relación en el mismo momento en el tiempo\n",
    "\n",
    "$$y_{t}=\\beta_{0}+\\beta_{1}z_{t}+u_{t}$$\n",
    "\n",
    "Ejemplos:\n",
    "* Modelo Simple:\n",
    "$$ inflación_{t}=\\beta_{0}+\\beta_{1}desempleo_{t}+u_{t}$$\n",
    "\n",
    "* Modelo múltiple:\n",
    "$$ homicidio_{t}=\\beta_{0}+\\beta_{1}condena_{t}+\\beta_{2}desmepleo_{t}+\\beta_{3}hombres_{t}+u_{t} $$\n",
    "\n",
    " ### Modelo dinámico\n",
    "\n",
    " Se incluyen efectos temporales, que se piensan que tienen que ver con **tendencias**, **inercia** o **estacionalidades**\n",
    "\n",
    " $$ inflación_{t}=\\beta_{0}+\\beta_{1}desempleo_{t}+\\beta_{2} inflación_{t-1} +u_{t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas y series de tiempo\n",
    "\n",
    "* Pandas fue desarrollado originalmente para trabajar con datos financieros.\n",
    "* Como las series temporales son un tipo de datos comunes encontrados en aplicaiones de finanzas, naturalmente pandas tiene muy buen soporte para la mayoria de operaciones comunes.\n",
    "\n",
    "\n",
    "* `pd.to_datetime()` : conviere una serie o valor en un timestamp\n",
    "  * Este formato permite un mejor manejo de las series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas remote data access support for calls to the World Bank Indicators API\n",
    "from pandas_datareader import data, wb #instalar conda install pandas-datareader  o  pip installpandas-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisemos que indicadores hay disponibles. En este caso revisare de PIB (GDP en ingés), pero se pueden explorar muchas más opciones.\n",
    "\n",
    "wb.search('gdp.*capita.*const')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtengamos la lista de paises disponibles\n",
    "countries=wb.get_countries()\n",
    "\n",
    "#Preview primeras filas lista de paises\n",
    "countries[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sabemos que queremos Chile, asi que busquemos su info\n",
    "\n",
    "countries[ countries['name'] == 'Chile' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarguemos la data desde la API del banco muncial a un dataframe\n",
    "\n",
    "df_GPDpc_Chile = wb.download(\n",
    "                    #Use the indicator attribute to identify which indicator or indicators to download\n",
    "                    indicator='NY.GDP.PCAP.KD',\n",
    "                    #Use the country attribute to identify the countries you want data for\n",
    "                    country=['CL'],\n",
    "                    #Identify the first year for which you want the data, as an integer or a string\n",
    "                    start='1980',\n",
    "                    #Identify the last year for which you want the data, as an integer or a string\n",
    "                    end=2020,\n",
    "                )\n",
    "\n",
    "#Veamos el data frame\n",
    "df_GPDpc_Chile.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.download( indicator=['NY.GDP.PCAP.PP.KD','NY.GDP.PCAP.KD'], country=['CL'], start=2008, end=2010 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_GPDpc_Chile, x=\"year\", y=\"NY.GDP.PCAP.KD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_GPDpc_Chile.plot(legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplos\n",
    "\n",
    "## 1. PIB de EEUU\n",
    "\n",
    "Empecemos con un ejemplo muy clásico de series de tiempo, con datos del PIB de Estados Unidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP = pd.read_csv('data/GDP.csv', parse_dates=['DATE'])\n",
    "GDP.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP.set_index('DATE', inplace=True)\n",
    "GDP.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = GDP['2009':].plot(legend=False)\n",
    "ax.set_ylabel(r'GDP ($\\$B$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos claramente una **tendencia** al alza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mortalidad por influenza\n",
    "\n",
    "Vemos un segundo ejemplo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ILI = pd.read_csv('data/CDC.csv')\n",
    "ILI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ILI['date'] = ILI['Year']+ILI['Week']/52.\n",
    "ILI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ILI.plot(x='date', y=['Percent of Deaths Due to Pneumonia and Influenza', 'Expected', 'Threshold'])\n",
    "ax = plt.gca()\n",
    "ax.legend(['Mortality', 'Expected', 'Threshold'])\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('% Mortality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El comportamiento es muy diferente, podemos ver una **estacionalidad**.\n",
    "\n",
    "Es decir hay un cambio periodico asociado al tiempo de la variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformaciones\n",
    "\n",
    "En base a estos conceptos, entonces, es muy comun realizar transformaciones a las series de tiempo ya sea para obtener rezagos, diferencias, tasas de crecimiento, etc.\n",
    "Ilustraremos varios de estos, con el dataset del DOw-Jonses indsutrial Average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DJIA = pd.read_csv('data/DJIA.csv', parse_dates=['DATE'], na_values='.').dropna()\n",
    "DJIA.plot(x='DATE', legend=False)\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel('DJIA')\n",
    "ax.set_xlabel('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Diferencias\n",
    "\n",
    "Una manera de remover tendencias de un dataset es diferenciandolo. Como nuestros datasets son discretos, usaremos diferencias finitas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differentiate(values, d=1):\n",
    "    # First value is required so that we can recover the original values with np.cumsum\n",
    "    x = np.concatenate([[values[0]], values[1:]-values[:-1]])\n",
    "\n",
    "    if d == 1:\n",
    "        return x\n",
    "    else:    \n",
    "        return difference(x, d - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = DJIA['DJIA'].values\n",
    "differences = differentiate(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, el grafico se ve mucho más estacionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(DJIA['DATE'].iloc[1:], differences[1:])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Differences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para recuperar la data original, basta con integrar los puntos diferenciados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate(values, d=1):\n",
    "    x = np.cumsum(values)\n",
    "    \n",
    "    if d == 1:\n",
    "        return x\n",
    "    else:\n",
    "        return integrate(x, d-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebuilt = integrate(differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y un chequeo rapido para ver que son los mismos valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(rebuilt-values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windowing\n",
    "We also often want to calculate running values of some quantity. This requires the use of windowing functions that return the proper element at each step. \n",
    "def rolling(x, order):\n",
    "    npoints = x.shape[0]\n",
    "    running = []\n",
    "    \n",
    "    for i in range(npoints-order+1):\n",
    "        running.append(x[i:i+order])\n",
    "        \n",
    "    return np.array(running)\n",
    "And a simple example\n",
    "values = np.arange(11)\n",
    "values\n",
    "rolling(values, 6)\n",
    "Since we return a numpy array with all the individual windows, this also provides us with a simple way to take running averages by chaining methods\n",
    "rolling(values, 2)\n",
    "rolling(values, 2).mean(axis=1)\n",
    "Or the running maximum, etc.\n",
    "rolling(values, 2).max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Smoothing\n",
    "Another form of smoothing a noise time series is called exponential smoothing. This is equivalent to an exponentially weighted running average where past values get exponentially reduced.\n",
    "def ES(values, alpha= 0.05):\n",
    "    N = len(values)\n",
    "    S = [values[0]*alpha]\n",
    "    \n",
    "    for i in range(1, N):\n",
    "        S.append(alpha*values[i]+(1-alpha)*S[-1])\n",
    "        \n",
    "    return np.array(S)\n",
    "As we can see with a few quick examples, the smaller the value of alpha the smoother (less noisy) the result\n",
    "smooth = []\n",
    "smooth.append(ES(differences[1:], 0.01))\n",
    "smooth.append(ES(differences[1:], 0.1))\n",
    "smooth.append(ES(differences[1:], 0.5))\n",
    "plt.plot(DJIA['DATE'].iloc[1:100], differences[1:100], label='Differences')\n",
    "plt.plot(DJIA['DATE'].iloc[1:100], smooth[2][:99], label=r'$\\alpha=0.5$')\n",
    "plt.plot(DJIA['DATE'].iloc[1:100], smooth[1][:99], label=r'$\\alpha=0.1$')\n",
    "plt.plot(DJIA['DATE'].iloc[1:100], smooth[0][:99], label=r'$\\alpha=0.01$')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Differences')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "\n",
    "Desafortunadamente, los datos no siempre están limpios o completos, lo que nos obliga a lidiar datos faltantes. Aquí ilustramos varios enfoques para introducir valores perdidos. Comenzamos generando un conjunto de datos con valores perdidos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-np.pi, np.pi, 100)\n",
    "y = np.cos(x)\n",
    "y_missing = y.copy()\n",
    "y_missing[40:55] = np.nan\n",
    "This is simply a cosine function with a few missing values at the peak.\n",
    "plt.plot(x, y, '*')\n",
    "plt.plot(x, y_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Quizás la estrategia más común es simplemente mantener el último valor 'bueno' conocido y usarlo para completar los puntos de datos faltantes. Este enfoque no puede lidiar con los valores faltantes al comienzo del conjunto de datos. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffill(y):\n",
    "    y0 = y.copy()\n",
    "    N = len(y0)\n",
    "    \n",
    "    current = None\n",
    "    for i in range(1, N):\n",
    "        if np.isnan(y0[i]):\n",
    "            y0[i] = current\n",
    "        else:\n",
    "            current = y0[i]\n",
    "    \n",
    "    return y0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Naturalmente, el enfoque opuesto también es común cuando usamos el siguiente valor bueno. De esta manera podemos manejar fácilmente los valores perdidos iniciales, pero no podemos hacer nada con los valores perdidos al final de la serie de tiempo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bfill(y):\n",
    "    y0 = y.copy()\n",
    "    N = len(y0)\n",
    "    \n",
    "    current = None\n",
    "    for i in range(N-1, 0, -1):\n",
    "        if np.isnan(y0[i]):\n",
    "            y0[i] = current\n",
    "        else:\n",
    "            current = y0[i]\n",
    "    \n",
    "    return y0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Back-fill y Forward-fill son enfoques simples pero poderosos para lidiar con los datos faltantes. Sin embargo, a menudo queremos tener más cuidado con el valor que atribuimos. Un enfoque común es interpolar entre el valor anterior y el siguiente y conectarlos con una línea recta.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(y):\n",
    "    y0 = y.copy()\n",
    "    N = len(y0)\n",
    "    \n",
    "    pos = 0\n",
    "    while pos < N:\n",
    "        if np.isnan(y0[pos]):\n",
    "            count = 0\n",
    "            \n",
    "            while np.isnan(y0[pos+count]):\n",
    "                count += 1\n",
    "            \n",
    "            current = y0[pos-1]\n",
    "            future = y0[pos+count]\n",
    "            slope = (future-current)/count\n",
    "            \n",
    "            y0[pos:pos+count] = current + np.arange(1, count+1)*slope\n",
    "            \n",
    "            pos += count\n",
    "        else:\n",
    "            pos += 1\n",
    "            \n",
    "    return y0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La imputación de datos (el cálculo de los valores perdidos esperados) es un gran subcampo de estadísticas con una amplia gama de técnicas y enfoques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_bfill = bfill(y_missing)\n",
    "y_ffill = ffill(y_missing)\n",
    "y_inter = interpolate(y_missing)\n",
    "And a quick plot to visualize the differences\n",
    "plt.plot(x, y_bfill, label='back fill')\n",
    "plt.plot(x, y_ffill, label='forward fill')\n",
    "plt.plot(x, y_inter, label='interpolate')\n",
    "plt.plot(x, y_missing, label='Data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "\n",
    "En muchos casos, también necesitamos cambiar la frecuencia a la que estamos operando. Por ejemplo, nuestro conjunto de datos DJIA tiene valores al final del día, pero podríamos estar interesados en puntos de datos semanales o mensuales. El remuestreo es una serie de técnicas diseñadas para lidiar con esta situación y es similar en espíritu a las técnicas de ventanas que vimos anteriormente. La principal diferencia es que en lugar de simplemente mover la ventana en un paso fijo, cada ventana corresponde a nuestro período de interés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = DJIA['DATE'].dt.year\n",
    "values = DJIA['DJIA'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En el caso más simple, simplemente calculamos cuál es la ventana correcta para cada punto de datos y la agregamos en consecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def groupBy(values, mapping, func = None):\n",
    "    agg = {}\n",
    "    pos = {}\n",
    "    \n",
    "    for i in range(values.shape[0]):\n",
    "        key = mapping.iloc[i]\n",
    "        \n",
    "        if key not in agg:\n",
    "            agg[key] = []\n",
    "        \n",
    "        pos[key] = i\n",
    "        \n",
    "        if not np.isnan(values[i]):\n",
    "            agg[key].append(values[i])\n",
    "        \n",
    "    order = sorted(agg.keys())\n",
    "    \n",
    "    if func is not None:\n",
    "        for key in agg:\n",
    "            agg[key] = func(np.array(agg[key]).astype('float'))\n",
    "            \n",
    "    return agg, pos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturalmente, esta función groupBy es útil no solo para remuestrear sino también para una amplia gama de análisis estadísticos. Además de un mapeo, también debemos especificar qué función de agregación queremos usar. ¿Nos interesa el valor medio? ¿el maximo? ¿Desviación Estándar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg, pos = groupBy(values, mapping, np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aca simplemente calculamos la media por año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nuestra función groupBy también devuelve las posiciones de índice de la última vez que se vio cada bin, podemos comparar fácilmente los datos originales con los muestreados nuevamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aggregated = []\n",
    "\n",
    "for key in pos:\n",
    "    aggregated.append([pos[key], agg[key]])\n",
    "\n",
    "aggregated = np.array(aggregated)\n",
    "aggregated\n",
    "plt.plot(DJIA['DATE'], DJIA['DJIA'])\n",
    "ax = plt.gca()\n",
    "ax.plot(DJIA.set_index('DATE').index[aggregated.T[0].astype('int')], aggregated.T[1])\n",
    "ax.plot(DJIA.set_index('DATE').index[aggregated.T[0].astype('int')], aggregated.T[1], 'ro', markersize=10,)\n",
    "ax.set_ylabel('DJIA')\n",
    "ax.set_xlabel('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jackknife estimators\n",
    "\n",
    "FFinalmente, en muchos casos queremos estimar cantidades estadísticas de series de tiempo. Un ejemplo obvio podría ser estimar la media móvil de una serie sin tendencia para verificar si de hecho está lo suficientemente cerca de cero para ser considerada estacionaria.\n",
    "\n",
    "El estimador JackKnife nos permite obtener no solo el valor esperado en cuestión, sino también una medida de su varianza. Esto se logra mediante el uso de un enfoque de omisión para calcular N estimaciones de nuestra métrica. A partir de esta población de estimación, podemos obtener los promedios como la mejor estimación posible y la desviación estándar como una medida de las barras de error involucradas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jackknife(x, func, variance = False):\n",
    "    N = len(x)\n",
    "    pos = np.arange(N)\n",
    "    values = [func(x[pos != i]) for i in pos]\n",
    "    jack = np.sum(values)/N\n",
    "    \n",
    "    if variance:\n",
    "        values = [np.power(func(x[pos != i]) - jack, 2.0) for i in pos]\n",
    "        var = (N-1)/N * np.sum(values)\n",
    "        return jack, var\n",
    "    else:\n",
    "        return jack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(0, 2, 100)\n",
    "print(x.std())\n",
    "jackknife(x, np.std, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Con jackknife obtenemos no solo una estimación del valor sino también una medida del error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "\n",
    "Otra técnica común para estimar propiedades estadísticas se conoce como bootstrapping y está estrechamente relacionada con Jackknife. En este enfoque, simplemente tomamos muestras (con reemplazo) de la población original para obtener una medida de cuánta variabilidad se puede esperar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapping(x, n_samples, func=np.mean):\n",
    "    y = x.copy()\n",
    "    N = len(y)\n",
    "    population = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        population.append(func(np.random.choice(y, N, replace=True)))\n",
    "        \n",
    "    return np.array(population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Podemos generar fácilmente un histograma de las muestras bostrappeadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(values, n_bins=100):\n",
    "    xmax = values.max()\n",
    "    xmin = values.min()\n",
    "    delta  = (xmax-xmin)/n_bins\n",
    "    \n",
    "    counts = np.zeros(n_bins+1, dtype='int')\n",
    "    \n",
    "    for value in values:\n",
    "        val_bin = np.around((value-xmin)/delta).astype('int')\n",
    "        counts[val_bin] += 1.0\n",
    "    \n",
    "    bins = xmin+delta*np.arange(n_bins+1)\n",
    "    \n",
    "    return bins, counts/values.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "x = np.random.normal(0, 2, size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "boot = bootstrapping(x, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins, counts = histogram(boot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins, counts)\n",
    "plt.vlines(x=boot.mean(), ymin=0, ymax=counts.max(), label='mean', color='g')\n",
    "plt.vlines(x=boot.mean()+boot.std(), ymin=0, ymax=counts.max(), label='std', linestyles='--', color='r')\n",
    "plt.vlines(x=boot.mean()-boot.std(), ymin=0, ymax=counts.max(), label='std', linestyles='--', color='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad Bloque 1:\n",
    "\n",
    "1. Siga este ejemplo practico de importar datos desde la API del Banco Mundial y preparar la base para su análisis de series de tiempo.\n",
    "2. Importe usted la serie de GDP total Y Percapita para otro país serie desde la API del Banco mundial, muestre sus principales características y realice un grafico. \n",
    "3. Obtenga las primeras diferencias y compare, ¿pareciera haber tendencias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas remote data access support for calls to the World Bank Indicators API\n",
    "from pandas_datareader import data, wb #instalar conda install pandas-datareader  o  pip installpandas-datareader\n",
    "\n",
    "#Revisemos que indicadores hay disponibles. En este caso revisare de PIB (GDP en ingés), pero se pueden explorar muchas más opciones.\n",
    "\n",
    "wb.search('gdp.*capita.*const')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtengamos la lista de paises disponibles\n",
    "countries=wb.get_countries()\n",
    "\n",
    "#Preview primeras filas lista de paises\n",
    "countries[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sabemos que queremos Chile, asi que busquemos su info\n",
    "\n",
    "countries[ countries['name'] == 'Chile' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarguemos la data desde la API del banco muncial a un dataframe\n",
    "\n",
    "df_GPDpc_Chile = wb.download(\n",
    "                    #Use the indicator attribute to identify which indicator or indicators to download\n",
    "                    indicator='NY.GDP.PCAP.KD',\n",
    "                    #Use the country attribute to identify the countries you want data for\n",
    "                    country=['CL'],\n",
    "                    #Identify the first year for which you want the data, as an integer or a string\n",
    "                    start='1980',\n",
    "                    #Identify the last year for which you want the data, as an integer or a string\n",
    "                    end=2020\n",
    "                )\n",
    "\n",
    "#Veamos el data frame\n",
    "df_GPDpc_Chile.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.download( indicator=['NY.GDP.PCAP.PP.KD','NY.GDP.PCAP.KD'], country=['CL'], start=2008, end=2010 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_GPDpc_Chile, x=\"year\", y=\"NY.GDP.PCAP.KD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformemos la columna de tiempo a un indice en el dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GPDpc_Chile.index=pd.to_datetime(df_GPDpc_Chile['year'], format=\"%Y\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
